

## Day7

假设有两个节点做replication，为了避免分别向两个节点同时做写的操作
许多资料系统都只允许在一个节点上做写额操作。如果有partition, 那么每个partition内只会有一个
master，以及0-多个slave，只有master能写资料。
再极端一点，只允许master上读取资料，那么replica完全充当背媛的角色，没有分散读取的能力


## Day 8 eventual consistency

只要资料不再更新，最终有一个时刻，所有的节点会协调处一个一致的状态

每个节点的时间并不能同步，所以不能得到全局的顺序，所以不是很可靠。但是舍弃掉strong consistency可以换取其他的特性。

## Day 9 CAP

幸福三选二 (一般倾向保留P)

C: Consistency: 任何时候，两个节点的到的状态都是一样的
A: Availability: 若一个节点正常活动，那么它就必须能够正常服务
P: Partition: 若因为网络问题或者节点故障，切割成两个不完整的sub cluster， 系统依旧能够正常运行


在发生partition的时候，应该怎么做

1. keep avilability: 如果依旧各自正常工作，会出现brain split, 保证（A P）

2. keep consistency: 为了避免不一致的问题，biubiu停掉其中一个节点 保证 （C P ）


## Chapter 10 in memory data

如何能够让ram里的内容断电以后不会不见呢

1. persistence
2. replication


## Chapter 11 zookeeper

1. 共享 metadata
2. 监控成员节点的状况 & 维护丛集的成员名单
3. 协助选出丛集中的leader(master)

ZK的资料是树状结构的，节点叫做znode,可以在里面放置资料

再理解:
```
有一种 znode 叫做 ephemeral node，用来监控成员的状况。这个 znode 跟建立 znode 的
成员的 session 状况是连动的，若 session 一段时间没有回报 (heartbeat)，这个 znode
节点就会被删除。因此若有其他成员在此 znode 上设定 watcher，就会在此节点挂掉 (即
session 挂掉时) 收到通知。
所有成员都会对 master 对应的 ephemeral node 注册 watcher，所以在 master 失效後，会
有成员侦测到而启动 leader election。

```

## Day 12 Zookeeper

为了能够保证global order, 只有Leader能够写入要求。采用了Quorum,在partition的时候仍旧能够维持服务。

采用了偏向CA的系统 ？？

ZK成员有两种角色：leader 或者follower。
一个Quroum最多只有一个leader，其他都是支持这个leader的followers.

leader election的目的就是选出Quorum中的leader
一个Quorum钟的成员数达到最低的投票标准，一般来说，是要大于ZK的节点数目的一半
eg: 一共5个节点，那么Quorum必须要有三个成员，所以
当发生partition的时候，其中一个的partition是不足以形成quorum，所以不能够对外服务
所以整个cluster只有一个quoroum，所以不会发生inconsistency的问题。




## Day 13 Kafka

distributed queue,很多
streaming平台都把他作为data source

特点：
* 分散式架构
* 基于磁盘空间，并且避免随机存取
* 因为存储空间大，queue的资料已经消耗也可以不用删除掉
  * 其他新加入的consumer可以读取过去的资料
  * 如果有batch-oriented的consumer，可以一次拉去足够大量的资料
 
* 对资料的包装是轻量级的，可以压缩。
* 因为可以直接处理档案资料，直接用 OS 的 page cache，不需要额外 Applicaion
Cache 来竞争珍贵的记忆体空间。 ？？


## Day 14 Kafka

kafka是一个broker角色，位于producer consumer中间，一般是一个多节点的cluster

一组资料流称为一个topic, 避免topic 资料过大，一个topic可以分成好几个

partition，每个partition会在不用的节点上

每个producer要决定将那个资料送到哪个partition。

有一个api可以指定partition key， 然后使用hash的方式确定partition


两种queue mode:
1. point to point
2. pub/sub

一个重点是
一个consumer只会找一个partition来拉去资料。

## Day 15 Kafka

一些设计的限制
1. consumer数量不能够少于partition的数量，否则会有partition空置
2. 如果consumer消耗资料的速度不均衡，那么partiion的消耗速度就会失去平衡。
3. ？？
4. 每个partition可以看作是独立的queue，也就是说，没有所谓跨partition的total order。 只能保证自己的local order
5. 如果有total order需求的ap，并不适合用kafka

简单来说，Kafka 假设，AP 是不需要 total order 的；抑或是 AP 只需要 by-partition 的 local
order，只要适当的做好 partition，那麽就可以维持好时序的资料消耗。

如果有total order需求的ap，并不适合用kafka 

## Day 16 Kafka

replication机制

每个replica set里，只会有一个master,这个master负责所有的读写工作，其他的slave都只是备援

每个master负责所有的读写工作，其他的slave只充当备份


## Day 17 Kafka 
看资料

## Day 18 kafka, stream computing
Kafka是实现lambda architecture的要诀。因为只有它能够同时满足real-time processing
以及batch processing 对于data source的需求

## Day 19 分散资料系统，科层组织

？？

总结

```
我们还介绍了一些重要工具，Zookeeper 像是个专人管理的中央布告栏，帮助组织间沟通
协调，确保大家的认知是相同的。Zookeeper 非常尽责，你可以先跟他说你关心哪些公告，
那些公告有更新的话还会主动通知你～
Kafka 像是个高效的公文传送工具，让单位之间的资料能顺畅流通。但 Kafka 可不会主动
通知你有公文，你要自己去检查你的公文箱。不过 Kafka 会帮忙保留一些历史公文，所以
只要不要拖太久才去检查公文箱，基本上公文都还找的回来。
```


## Day 20 in-memory 技术

除非需要recovery，无需从disk读取资料， 不碰disk自然有加速效果。

## Day 21 分布式运算系统

stream computing 结合了data parallelism, 与pipeline 更加的复杂


## Day 22 分布式系统的沟通方式

作业系统

1. shared memory:
很多人使用的需要排队(lock)。

2. message passing: 所有的process间都透过讯息的方式交换资料。缺乏global order

分布式运算系统
1. shared data store
2. peer communication: 通常是non-blocking的通讯方式，并且还能够高效能的序列化框架

## Day 23: stream computing 应用范围

适用于大量的event涌进的应用。

## Day 24 Stream computing 特性

low-latency 应用。

透过pipeline的方式，只要前一个阶段处理完record,马上就可以进如下一个阶段。这样可以避免掉不必要的latency

应用：
1. 即时的统计


## Day 25 stream computing 框架

1. storm
2. samza
3. spark streaming

## Day 26 stream computing 框架的组成角色

1. 处理client提出的运算要求
2. 




#### Reference: 
http://dcaoyuan.github.io/papers/pdfs/Scalability.pdf







